# The noisier spark logs go to file only

#log4j.rootCategory=INFO,stdout
log4j.rootLogger=ERROR,stdout
log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=[%5p] [%t %d{hh:mm:ss}] (%F:%M:%L) %m%n
log4j.logger.spark.storage=ERROR,stdout
log4j.additivity.spark.storage=false
log4j.logger.spark.scheduler=ERROR,stdout
log4j.additivity.spark.scheduler=false
log4j.logger.spark.CacheTracker=ERROR,stdout
log4j.additivity.spark.CacheTracker=false
log4j.logger.spark.CacheTrackerActor=ERROR,stdout
log4j.additivity.spark.CacheTrackerActor=false
log4j.logger.spark.MapOutputTrackerActor=ERROR,stdout
log4j.additivity.spark.MapOutputTrackerActor=false
log4j.logger.spark.MapOutputTracker=ERROR,stdout
log4j.additivty.spark.MapOutputTracker=false
log4j.logger.com.github.fommil.netlib=DEBUG,stdout
log4j.logger.com.github.fommil.netlib.BLAS=TRACE,stdout
log4j.logger.org.apache.spark.mllib=DEBUG,stdout
log4j.logger.org.jblas=DEBUG,stdout
log4j.logger.org.scalanlp=DEBUG,stdout